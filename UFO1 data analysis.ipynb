{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFO 1 data analysis part 1\n",
    "\n",
    "Big Data házi feladat, UFO1 feladatkör EDA analízise, adatfelderítése.\n",
    "\n",
    "A használathoz feltételezzük, hogy már létezik egy állomány, data.csv néven, ami tartalmazza a szükséges adatokat.\n",
    "\n",
    "Ennek a notebooknak a célja, hogy a letöltött adatokkal megismerkedjünk, néhány megfigyelést állapítsunk meg róluk, esetlegesen a nem megfelelő adatokat kiemeljük, és töröljük a készletből.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adatok betöltése, átalakítása\n",
    "\n",
    "Az egyszerű betöltés után néhány kisebb módosítást végeztünk az adatokon:\n",
    "* Date / Time osztlop átnevezése Date-re, az kezelhetőbbség kedvéért\n",
    "* Shape oszlop értékei nem voltak konzisztensen kis vagy nagybetűsek, ezért ezeket egységesen csupa lowercase-re konvertáltuk\n",
    "* A dátumok feldolgozásához a Python saját parser-ét használtuk\n",
    "    * Amit az nem volt képes feldolgozni, azt egy nem előforduló értékre állítottuk, amit majd később ki lehet szűrni / el lehet dobni\n",
    "    * Mivel az eredeti adatok szintaxisa miatt jövőbeni adatokat talált a parser, ezért ezeket kézzel módosítottuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import matplotlib\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "matplotlib.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Load data (labels are not included)\n",
    "raw_data = pandas.read_csv(\"data.csv\", sep=\";\", encoding=\"UTF8\", header=None, skiprows=1)\n",
    "\n",
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \\\n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \\\n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \\\n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \\\n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "data, wrong_data, skipped_lines = [], [], 0\n",
    "for i, d in raw_data.iterrows():\n",
    "    try:\n",
    "        # Transform or validate data\n",
    "        date = pandas.to_datetime(d[0])\n",
    "        posted = pandas.to_datetime(d[6])\n",
    "        row = (date, d[1], d[2], d[3], d[4], d[5], posted, d[7])\n",
    "        \n",
    "        # Do some checks...\n",
    "        if date.date() > posted.date():\n",
    "            wrong_data.append(row)\n",
    "            continue\n",
    "        \n",
    "        if state not in states:\n",
    "            wrong_data.append(row)\n",
    "            continue\n",
    "        \n",
    "        # Add data to cleaned array\n",
    "        data.append(row)\n",
    "    except Exception as e:\n",
    "        skipped_lines += 1\n",
    "        #print(d)\n",
    "\n",
    "names = [\"Date\", \"City\", \"State\", \"Shape\", \"Duration\", \"Summary\", \"Posted\", \"Description\"]\n",
    "data = pandas.DataFrame.from_records(data, columns=names)\n",
    "wrong_data = pandas.DataFrame.from_records(wrong_data, columns=names)\n",
    "\n",
    "print('Loading data took ' + str(time.time() - start) + 's')\n",
    "print('Raw data: ' + str(len(raw_data)) + ' lines')\n",
    "print('Processed data: ' + str(len(data)) + ' lines')\n",
    "print('Skipped because of parser exception: ' + str(skipped_lines) + ' lines')\n",
    "print('Wrong data: ' + str(len(wrong_data)) + ' lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from collections import Counter\n",
    "from duration_parser import UFOParser\n",
    "\n",
    "with open('data_old.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = list(data['City'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chk_word(word):\n",
    "    if word is None:\n",
    "        return False\n",
    "    return re.match(\"^[a-zA-Z0-9-() ]*$\", word) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_citites = [x for x in cities if chk_word(x) is False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bad_citites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_citites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city = (data['City']['34139'], data['State']['34139'])\n",
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_geodata(name):\n",
    "    url = 'http://nominatim.openstreetmap.org/search/'\n",
    "    response = requests.get(url + name, params={'addressdetails': 1, 'format': 'json', 'limit': 10}).json()\n",
    "    return [(d['address'], d['lon'], d['lat']) for d in response if d['type'] == 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata = download_geodata('Bedford')\n",
    "geodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sts = {\"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \\\n",
    "       \"California\": \"CA\", \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \\\n",
    "       \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \\\n",
    "       \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\", \\\n",
    "       \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\", \\\n",
    "       \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \\\n",
    "       \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \\\n",
    "       \"NewHampshire\": \"NH\", \"NewJersey\": \"NJ\", \"NewMexico\": \"NM\", \"NewYork\": \"NY\", \\\n",
    "       \"NorthCarolina\": \"NC\", \"NorthDakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\", \\\n",
    "       \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"RhodeIsland\": \"RI\", \"SouthCarolina\": \"SC\", \\\n",
    "       \"SouthDakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \\\n",
    "       \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\", \"WestVirginia\": \"WV\", \\\n",
    "       \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_geodata(org_data, result):\n",
    "    city, state = org_data\n",
    "    if state.upper() in list(sts.values()):\n",
    "        print('American')\n",
    "        for item in result:\n",
    "            print(item)\n",
    "    \n",
    "check_geodata(city, geodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adatok feltérképezése\n",
    "\n",
    "### Használt oszlopok és típusai, valamint néhány mintaadat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.dtypes\n",
    "sample_data = []\n",
    "for i in range(10):\n",
    "    sample_data.append(data.iloc[random.randint(0,len(data))])\n",
    "pandas.DataFrame.from_records(sample_data, columns=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adatok vizualizációja az észlelés ideje alapján"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "by_year = data.groupby(data[\"Date\"].dt.year).count()[\"Date\"]\n",
    "print(by_year.describe())\n",
    "data.groupby(data[\"Date\"].dt.year).count()[\"Date\"].plot(figsize=(15,5),kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vizualizációból látszik, hogy az adatok nagy része 2000 utánról származik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adatok vizualizációja az észlelt ufók száma alapján, alak szerint csoportosítva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shape_counts = data[\"Shape\"].value_counts()\n",
    "print(shape_counts.describe())\n",
    "shape_counts.plot(figsize=(15,5),kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adatok leíró statisztikái a City és a State oszlop szerint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_city = data.groupby(\"City\").count()[\"Date\"]\n",
    "by_city.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az adatok város szerinti vizsgálatából látszik, hogy nagyon sok különböző várost adtak meg az adathalmazban, amiből sok olyan van, ami vagy egyszeri észlelés, vagy ami valószínűbb, hogy valami elírás, vagy hibásan felvitt adat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_state = data.groupby(\"State\").count()[\"Date\"]\n",
    "by_state.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az állam szerinti csoportosításnál úgy tűnik sikeres volt az adatok validációja és transzformációja, mert ezek szerint 1 kivételével mindegyik államból jelentettek észlelést. A qvartilisek, valamint a min és max értékek sem szembetűnően kiugróak a vártakhoz képest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizációs feladat megoldásának terve\n",
    "\n",
    "A feladat szerint meg kell jelenítenünk az UFO észleléseket térbeli, és időbeli eloszlásuk szerint.\n",
    "Erre megoldásnak az alábbi vizualizációt tervezzük megvalósítani:\n",
    "* PySpark segítségével, Map - Reduce módszerrel elkészítjük az egyes évekhez tartozó megfigyelések számát, állam szerint\n",
    "* Ezeket egy 2D pont diagrammon ábrázoljuk, X tengelyen az államokat, Y tengelyen az éveket.\n",
    "* Ábrázolásnál az adatok számosságának jelölésére színeket és/vagy méreteket használunk.\n",
    "\n",
    "A koncepciót az alábbi ábra szemlélteti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = [{\"x\":2,\"y\":1,\"count\":10},{\"x\":1,\"y\":2,\"count\":5},{\"x\":1,\"y\":5,\"count\":2},{\"x\":4,\"y\":1,\"count\":7}]\n",
    "concept_df = pandas.DataFrame.from_records(concept)\n",
    "matplotlib.pyplot.scatter(concept_df[\"x\"],concept_df[\"y\"],s=concept_df[\"count\"]**2 * math.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.75.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
